---
title: "Class 9: Unsupervised Learning Analysis of Human Breast Cancer Cells"
author: "Arya Jahan"
date: "April 30, 2019"
output: github_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

# 1. Exploratory Data Analysis

## Preparing the Data

Read and Assign WisconsinCancer file
```{r}
fna.data <- "data/WisconsinCancer.csv"

wisc.df <- read.csv("WisconsinCancer.csv")
```

Select 3rd-32nd columns for use in new matrix
```{r}
wisc.data <- as.matrix(wisc.df[,3:32])
```

Assign Row Names
```{r}
row.names(wisc.data) <- wisc.df$id
```

Read Malignant or Benign diagnoses as 1 and 0 in new 'diagnosis' vector
```{r}
diagnosis <- as.numeric(wisc.df$diagnosis == "M")

diagnosis
```

Q1: How many observations are in the dataset?
```{r}
nrow(wisc.data)
```

Q2: How many variables/features in the data are suffixed with _mean?
```{r}
length(grep("_mean", colnames(wisc.data)))
```

Q3: How many observations have a malignant diagnosis?
```{r}
table(wisc.df$diagnosis)
```

# 2. Principal Component Analysis

## Performing PCA

Check column means and standard deviations, then round
```{r}
round(colMeans(wisc.data), 1)
```

```{r}
round(apply(wisc.data,2,sd), 1)
```


Execute PCA with the **prcomp()** function
```{r}
wisc.pr <- prcomp((wisc.data), scale = TRUE)

summary(wisc.pr)
```

Compare PC1 and PC2
```{r}
plot(wisc.pr$x[,1], wisc.pr$x[,2], col=diagnosis+1, xlab="PC1", ylab="PC2")
```

Q4. From your results, what proportion of the original variance is captured by the first principal components (PC1)?
44%

Q5. How many principal components (PCs) are required to describe at least 70% of the original variance in the data?
3 Principal Components

Q6. How many principal components (PCs) are required to describe at least 90% of the original variance in the data?
7 Principal Components

## Interpreting PCA Results

Create a biplot
```{r}
biplot(wisc.pr)
```

Q7. What stands out to you about this plot? Is it easy or difficult to understand? Why?
It is difficult to understand.

Compare PC1 and PC3
```{r}
plot(wisc.pr$x[,1], wisc.pr$x[,3], col=diagnosis+1, xlab="PC1", ylab="PC3")
```

Q8. Generate a similar plot for principal components 1 and 3. What do you notice about these plots?
The plots are similar along the x-axis (PC1), and different along the y-axis (PC2 v PC3). The first plot explains more variance

## Variance Explained

Calculate the variance of each PC
```{r}
pr.var <- wisc.pr$sdev^2
head(pr.var)
```

Calculate the total variance explained
```{r}
pve <- pr.var/sum(pr.var)
head(pve)
```

Make a Scree Plot
```{r}
plot(pve, xlab = "Principal Component", 
     ylab = "Proportion of Variance Explained", 
     ylim = c(0, 1), type = "o")
```

Alternative scree plot of the same data, note data driven y-axis
```{r}
barplot(pve, ylab = "Precent of Variance Explained",
     names.arg=paste0("PC",1:length(pve)), las=2, axes = FALSE)
axis(2, at=pve, labels=round(pve,2)*100 )
```


Plot cumulative proportion of variance explained
```{r}
plot(cumsum(pve), xlab = "Principal Component", 
     ylab = "Cumulative Proportion of Variance Explained", 
     ylim = c(0, 1), type = "o")
```

Setup side-by-side plots
```{r}
par(mfcol=c(1,2))

plot(pve, xlab = "Principal Component", 
     ylab = "Proportion of Variance Explained", 
     ylim = c(0, 1), type = "o")

plot(cumsum(pve), xlab = "Principal Component", 
     ylab = "Cumulative Proportion of Variance Explained", 
     ylim = c(0, 1), type = "o")
```


# 3. Hierarchical Clustering

## Hierarchical clustering of case data

Scale the data
```{r}
data.scaled <- scale(wisc.data)
```

Calculate distances
```{r}
data.dist <- dist(data.scaled)
```

Create hierarchical clustering model
```{r}
wisc.hclust <- hclust(data.dist, method = "complete")
```

## Results of Hierarchical Clustering

Q11. Using the plot() and abline() functions, what is the height at which the clustering model has 4 clusters?

```{r}
plot(wisc.hclust)
abline(h=19, col = "red", lty=2)
```



# 5. Combining Methods

## Clustering on PCA Results

Describe at least 90% of the data
```{r}
wisc.pr.hclust <- (hclust(dist(wisc.pr$x[,1:7]), method="ward.D2"))
```

Plot hclust
```{r}
plot(wisc.pr.hclust)
```

Cut into two groups
```{r}
grps <- cutree(wisc.pr.hclust, k=2)
table(grps)
```

Compare Cluster membership to actual diagnoses
```{r}
table(grps, diagnosis)
```

Plot by Cluster membership
```{r}
plot(wisc.pr$x[,1:2], col=grps)
```

Plot by diagnosis
```{r}
plot(wisc.pr$x[,1:2], col=diagnosis+1)
```

# 7. Prediction

Use our PCA model to predict using new data

Read new data
```{r}
url <- "https://tinyurl.com/new-samples-CSV"
new <- read.csv(url)
```

```{r}
npc <- predict(wisc.pr, newdata=new)
npc
```

Plot new patients against our PCA plot
```{r}
plot(wisc.pr$x[,1:2], col=grps)
points(npc[,1], npc[,2], col="blue", pch=16)
```

## The patient in the black cluster needs to be paid attention!
























